<!DOCTYPE html>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Customize Your Visual Autoregressive Recipe with <br> Set Autoregressive Modeling</title>
    <link href="./DreamBooth_files/style.css" rel="stylesheet">
    <script type="text/javascript" src="./DreamBooth_files/jquery.mlens-1.0.min.js"></script> 
    <script type="text/javascript" src="./DreamBooth_files/jquery.js"></script>
</head>

<body>
<div class="content">
  <h1><strong>Customize Your Visual Autoregressive Recipe with Set Autoregressive Modeling</strong></h1>
  <p id="authors"><span><a href="https://poppuppy.github.io/">Wenze Liu</a><a href="https://le-zhuo.com/">Le Zhuo</a><a href="https://synbol.github.io/">Yi Xin</a><a href="https://github.com/travis-xia/">Sheng Xia</a><a href="https://gaopengcuhk.github.io/">Peng Gao</a><a href="https://xyue.io/">Xiangyu Yue</a></span><br>
    <span style="font-size: 24px">MMLab, CUHK & Shanghai AI Lab & Nanjing University</span></p>
  <br>
  <img src="./DreamBooth_files/visualization.png" class="teaser-gif" style="width:100%;"><br>
  <h3 style="text-align:center"><em>SAR provides a smooth path connecting AR and MAR, where the transition states enjoy both their merits. </em></h3>
  <font size="+2">
          <p style="text-align: center;">
            <a href="https://arxiv.org" target="_blank">[Paper]</a> &nbsp;&nbsp;&nbsp;&nbsp;
            <a href="DreamBooth_files/bibtex.txt" target="_blank">[BibTeX]</a>
          </p>
  </font>
</div>

<div class="content">
  <h2 style="text-align:center;">Abstract</h2>
  <p>We introduce a new paradigm for AutoRegressive (AR) image generation, termed <em>Set AutoRegressive Modeling</em> (SAR). SAR generalizes the conventional AR to the next-set setting, <em>i.e.</em>, splitting the sequence into arbitrary sets containing multiple tokens, rather than outputting each token in a fixed raster order. To accommodate SAR, we develop a straightforward architecture termed <em>Fully Masked Transformer</em>. We reveal that existing AR variants correspond to specific design choices of sequence order and output intervals within the SAR framework, with AR and Masked AR (MAR) as two extreme instances. Notably, SAR facilitates a seamless transition from AR to MAR, where intermediate states allow for training a causal model that benefits from both advantages of AR and MAR, such as few-step inference, KV cache acceleration, and image editing. On the ImageNet benchmark, we carefully explore the properties of SAR by analyzing the impact of sequence order and output intervals on performance, as well as the generalization ability regarding inference order and steps. We further validate the potential of SAR by training a $900$M text-to-image model capable of synthesizing photo-realistic images with any resolution. We hope our work may inspire more exploration and application of AR-based modeling across diverse modalities.</p>
</div>

<div class="content">
  <h2>Background</h2>
  <p>Given a particular subject, it is very challenging to generate it in different contexts with state-of-the-art text-to-image models while maintaining high fidelity to its key visual features. Existing methods often struggle to reconstruct the unique characteristics of a subject across varying contexts.</p>
  <br>
  <img class="summary-img" src="./DreamBooth_files/background.png" style="width:100%;"> <br>
</div>

<div class="content">
  <h2>Approach</h2>
  <p>Our method takes as input a few images (typically 3-5 images suffice, based on our experiments) of a subject and the corresponding class name, returning a fine-tuned/"personalized" text-to-image model that encodes a unique identifier for the subject. At inference, we can implant this unique identifier in different sentences to synthesize the subject in various contexts.</p>
  <br>
  <img class="summary-img" src="./DreamBooth_files/high_level.png" style="width:100%;"> <br>
  <p>Given ~3-5 images of a subject, we fine-tune a text-to-image diffusion model in two steps: (a) fine-tuning the low-resolution model with the input images paired with a text prompt containing a unique identifier and the class name, while applying a class-specific prior preservation loss; (b) fine-tuning the super-resolution components with pairs of low-resolution and high-resolution images to maintain fidelity to small details of the subject.</p>
  <br>
  <img class="summary-img" src="./DreamBooth_files/system.png" style="width:100%;"> <br>
</div>

<div class="content">
  <h2>Results</h2>
  <p>By fine-tuning a model using our method, we generate various images of a subject in different environments, preserving subject details and ensuring realistic interactions between the scene and the subject.</p>
  <img class="summary-img" src="./DreamBooth_files/results.png" style="width:100%;">
</div>

<div class="content">
  <h2>Art Rendition</h2>
  <p>We showcase original artistic renditions of our subjects in the style of famous painters, demonstrating creativity and novel composition.</p>
  <br>
  <img class="summary-img" src="./DreamBooth_files/art.png" style="width:100%;"> <br>
</div>

<div class="content">
  <h2>Text-Guided View Synthesis</h2>
  <p>Our technique synthesizes images with specified viewpoints for a subject, highlighting the preservation of unique patterns and realistic background changes.</p>
  <br>
  <img class="summary-img" src="./DreamBooth_files/novel_views.png" style="width:100%;"> <br>
</div>

<div class="content">
  <h2>Property Modification</h2>
  <p>We demonstrate color modifications and combinations between specific subjects and other entities, preserving the unique visual features that define the subject's identity.</p>
  <br>
  <img class="summary-img" src="./DreamBooth_files/property_modification.png" style="width:100%;"> <br>
</div>

<div class="content">
  <h2>Accessorization</h2>
  <p>We showcase the ability to outfit subjects with various accessories, ensuring the preservation of identity while allowing for diverse styling options.</p>
  <br>
  <img class="summary-img" src="./DreamBooth_files/accessories.png" style="width:100%;"> <br>
</div>

<div class="content">
  <h2>Societal Impact</h2>
  <p>This project aims to provide users with an effective tool for synthesizing personal subjects in different contexts. While general text-to-image models might be biased towards specific attributes, our approach enables better reconstructions of desirable subjects. However, there are concerns regarding misuse that must be addressed in future research.</p>
  <br>
</div>

<div class="content">
  <h2>BibTex</h2>
  <code>@article{your2023customize,<br>
  &nbsp;&nbsp;title={Customize Your Visual Autoregressive Recipe with Set Autoregressive Modeling},<br>
  &nbsp;&nbsp;author={Your Name and Collaborator Name},<br>
  &nbsp;&nbsp;booktitle={arXiv preprint},<br>
  &nbsp;&nbsp;year={2023}<br>
  }</code>
</div>

<div class="content" id="acknowledgements">
  <p><strong>Acknowledgements</strong>: We thank <a href="https://dreambooth.github.io">DreamBooth</a> for the page templates.</p>
</div>
</body>
</html>
