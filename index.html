<!DOCTYPE html>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Customize Your Visual Autoregressive Recipe with <br> Set Autoregressive Modeling</title>
    <link href="./DreamBooth_files/style.css" rel="stylesheet">
    <script type="text/javascript" src="./DreamBooth_files/jquery.mlens-1.0.min.js"></script> 
    <script type="text/javascript" src="./DreamBooth_files/jquery.js"></script>
</head>

<body>
<div class="content">
  <h1><strong>Customize Your Visual Autoregressive Recipe with Set Autoregressive Modeling</strong></h1>
  <p id="authors"><span><a href="https://poppuppy.github.io/">Wenze Liu</a><a href="https://le-zhuo.com/">Le Zhuo</a><a href="https://synbol.github.io/">Yi Xin</a><a href="https://github.com/travis-xia/">Sheng Xia</a><a href="https://gaopengcuhk.github.io/">Peng Gao</a><a href="https://xyue.io/">Xiangyu Yue</a></span><br>
    <span style="font-size: 24px">MMLab, CUHK & Shanghai AI Lab & Nanjing University</span></p>
  <br>
  <img src="./DreamBooth_files/visualization.png" class="teaser-gif" style="width:100%;"><br>
  <h3 style="text-align:center"><em>SAR provides a smooth pathway travelling from AR to MAR, where the transition states enjoy both their merits. </em></h3>
  <font size="+2">
          <p style="text-align: center;">
            <a href="https://arxiv.org" target="_blank">[Paper]</a> &nbsp;&nbsp;&nbsp;&nbsp;
            <a href="DreamBooth_files/bibtex.txt" target="_blank">[BibTeX]</a>
          </p>
  </font>
</div>

<div class="content">
  <h2 style="text-align:center;">Abstract</h2>
  <p>We introduce a new paradigm for AutoRegressive (AR) image generation, termed <em>Set AutoRegressive Modeling</em> (SAR). SAR generalizes the conventional AR to the next-set setting, <em>i.e.</em>, splitting the sequence into arbitrary sets containing multiple tokens, rather than outputting each token in a fixed raster order. To accommodate SAR, we develop a straightforward architecture termed <em>Fully Masked Transformer</em>. We reveal that existing AR variants correspond to specific design choices of sequence order and output intervals within the SAR framework, with AR and Masked AR (MAR) as two extreme instances. Notably, SAR facilitates a seamless transition from AR to MAR, where intermediate states allow for training a causal model that benefits from both advantages of AR and MAR, such as few-step inference, KV cache acceleration, and image editing. On the ImageNet benchmark, we carefully explore the properties of SAR by analyzing the impact of sequence order and output intervals on performance, as well as the generalization ability regarding inference order and steps. We further validate the potential of SAR by training a 900M text-to-image model capable of synthesizing photo-realistic images with any resolution. We hope our work may inspire more exploration and application of AR-based modeling across diverse modalities.</p>
</div>

<div class="content">
  <h2>Introduction</h2>
  <p>Originating from language processing, AR and MAR (BERT-like) are two representative methods for generating images in discrete latent space. Recent work has proven that the generative capabilities of AR models can rival or even surpass those of diffusion models. However, AR models has long inference time, and they are intrisically not good at image editing tasks due to the fixed order. MAR reduces the number of inference steps at the cost of requiring global calculations, and the random order facilitates editing tasks. SAR unifies AR and MAR by generalizing the sequence order and output intervals. Further, SAR offers a path gradually travelling from AR to MAR, where in the transition states, one can train models possessing good properties of both AR and MAR, including few-step inference, KV cache acceleration, image editing, etc. </p>
  <br>
  <img class="summary-img" src="./DreamBooth_files/comparison.png" style="width:100%;"> <br>
</div>

<div class="content">
  <h2>Approach</h2>
  <p>During training, the input sequence is first rearranged to a causal one. And we control the output intervals using generalized causal masks in the proposed Fully Masked Transformer.</p>
  <br>
  <img class="summary-img" src="./DreamBooth_files/model.png" style="width:100%;"> <br>
</div>

<div class="content">
  <h2>Few-step Generation</h2>
  <p>We train a T2I model, Lumina-SAR, in the transition states of SAR. Its first feature is few-step inference. Lumina-SAR begins to produce meaningful images at around 4 to 8 steps. With 64 steps, it can deliver high-quality outputs, requiring a processing time of only less than 3s on one A100. Typically, the full 4096 steps (AR) take >60 times longer than that required for 64 steps.</p>
  <img class="summary-img" src="./DreamBooth_files/t2i_step.png" style="width:100%;">
</div>

<div class="content">
  <h2>Zero-shot Painting</h2>
  <p>Another advantage of SAR is the flexibility in inference order, which facilitates image editing tasks such as image inpainting and outpainting. We perform zero-shot painting with Lumina-SAR, where the mask can be any shape.</p>
  <br>
  <img class="summary-img" src="./DreamBooth_files/painting.png" style="width:100%;"> <br>
</div>

<div class="content">
  <h2>More Visualizations</h2>
    <p>
        <h3>Class-to-image on ImageNet</h3>
    </p>
  <br>
  <img class="summary-img" src="./DreamBooth_files/c2i.jpg" style="width:100%;"> <br>
</div>

<div class="content">
  <h2>Property Modification</h2>
  <p>We demonstrate color modifications and combinations between specific subjects and other entities, preserving the unique visual features that define the subject's identity.</p>
  <br>
  <img class="summary-img" src="./DreamBooth_files/property_modification.png" style="width:100%;"> <br>
</div>

<div class="content">
  <h2>Accessorization</h2>
  <p>We showcase the ability to outfit subjects with various accessories, ensuring the preservation of identity while allowing for diverse styling options.</p>
  <br>
  <img class="summary-img" src="./DreamBooth_files/accessories.png" style="width:100%;"> <br>
</div>

<div class="content">
  <h2>Societal Impact</h2>
  <p>This project aims to provide users with an effective tool for synthesizing personal subjects in different contexts. While general text-to-image models might be biased towards specific attributes, our approach enables better reconstructions of desirable subjects. However, there are concerns regarding misuse that must be addressed in future research.</p>
  <br>
</div>

<div class="content">
  <h2>BibTex</h2>
  <code>@article{your2023customize,<br>
  &nbsp;&nbsp;title={Customize Your Visual Autoregressive Recipe with Set Autoregressive Modeling},<br>
  &nbsp;&nbsp;author={Your Name and Collaborator Name},<br>
  &nbsp;&nbsp;booktitle={arXiv preprint},<br>
  &nbsp;&nbsp;year={2023}<br>
  }</code>
</div>

<div class="content" id="acknowledgements">
  <p><strong>Acknowledgements</strong>: We thank <a href="https://dreambooth.github.io">DreamBooth</a> for the page templates.</p>
</div>
</body>
</html>
